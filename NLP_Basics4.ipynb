{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n",
    "from tensorflow.keras.utils import to_categorical,pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['recurrent neural network',\n",
    "\t\t'neural network',\n",
    "\t\t'artificial neural',\n",
    "\t\t'connections between nodes',\n",
    "\t\t'can create a cycle',\n",
    "\t\t'allowing output',\n",
    "\t\t'some nodes to affect subsequent',\n",
    "\t\t'exhibit temporal',\n",
    "\t\t'dynamic behavior',\n",
    "\t\t'type of Neural Network',\n",
    "    'affect subsequent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus  = []\n",
    "for i in range(len(docs)):\n",
    "    review = re.sub('[^a-zA-z]',' ',docs[i])\n",
    "    review = review.lower()\n",
    "    corpus.append(review)\n",
    "    word_tokenized = nltk.word_tokenize(corpus[i])\n",
    "    stemmed_corpus = [stemmer.stem(word) for word in word_tokenized if word not in(set(stopwords.words('english')))]\n",
    "    corpus[i] = \" \".join(stemmed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recurr neural network',\n",
       " 'neural network',\n",
       " 'artifici neural',\n",
       " 'connect node',\n",
       " 'creat cycl',\n",
       " 'allow output',\n",
       " 'node affect subsequ',\n",
       " 'exhibit tempor',\n",
       " 'dynam behavior',\n",
       " 'type neural network',\n",
       " 'affect subsequ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  1  2]\n",
      " [ 0  1  2]\n",
      " [ 0  7  1]\n",
      " [ 0  8  3]\n",
      " [ 0  9 10]\n",
      " [ 0 11 12]\n",
      " [ 3  4  5]\n",
      " [ 0 13 14]\n",
      " [ 0 15 16]\n",
      " [17  1  2]\n",
      " [ 0  4  5]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences =  tokenizer.texts_to_sequences(corpus)\n",
    "X = pad_sequences(sequences, maxlen = max(len(seq) for seq in sequences))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = CountVectorizer()\n",
    "X_Bag_of_words = bag_of_words.fit_transform(corpus).toarray()\n",
    "print(X_Bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.52938109 0.47309247 0.\n",
      "  0.         0.70422949 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.74563614 0.66635332 0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.83008327 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.55763945 0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.76014955 0.\n",
      "  0.         0.         0.         0.         0.         0.64974816\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.70710678\n",
      "  0.70710678 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.70710678 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.70710678 0.         0.         0.         0.        ]\n",
      " [0.57735027 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.57735027\n",
      "  0.         0.         0.57735027 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.70710678 0.         0.         0.\n",
      "  0.         0.         0.         0.70710678 0.        ]\n",
      " [0.         0.         0.         0.70710678 0.         0.\n",
      "  0.         0.70710678 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.52938109 0.47309247 0.\n",
      "  0.         0.         0.         0.         0.70422949]\n",
      " [0.70710678 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.70710678 0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "Tfidf = TfidfVectorizer()\n",
    "X_tfidf = Tfidf.fit_transform(corpus).toarray()\n",
    "print(X_tfidf)\n",
    "print(type(X_tfidf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
