{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "words =[\"This\", \"book\", \"was\", \"fantastic\", \"I\", \"really\", \"love\", \"science\", \"fiction\", \"but\", \"the\", \"protagonist\", \"was\", \"rude\", \"sometimes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {word: i for i, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'This': 0,\n",
       " 'book': 1,\n",
       " 'was': 12,\n",
       " 'fantastic': 3,\n",
       " 'I': 4,\n",
       " 'really': 5,\n",
       " 'love': 6,\n",
       " 'science': 7,\n",
       " 'fiction': 8,\n",
       " 'but': 9,\n",
       " 'the': 10,\n",
       " 'protagonist': 11,\n",
       " 'rude': 13,\n",
       " 'sometimes': 14}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([word_to_idx[word] for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1, 12,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(num_embeddings=len(words),embedding_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(15, 10)\n"
     ]
    }
   ],
   "source": [
    "print(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = embedding(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 10])\n",
      "tensor([-0.9175,  0.1808, -0.5805, -0.9813,  1.0255,  0.2556, -0.2636,  0.6221,\n",
      "        -1.3349, -0.6163], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"Abhishek Waghchaure\n",
    "Sai Vrundavan, flat no-703, Sr No-56/5B,\n",
    "Behind Abhiruchi Mall,\n",
    "Sinhgad road, Vadgaon Bk.,\n",
    "PUNE, Maharashtra - 411041\n",
    "Email: abhisw28@gmail.com\n",
    "Mobile: 8668566528\n",
    "Dear Human Resources Team\n",
    "I am excited to apply for the Data Science Engineer position. With a strong academic foundation in\n",
    "data science and analytics, complemented by practical experience as a software developer, I am\n",
    "eager to bring my skills to your team and contribute to the innovative AI-driven solutions your\n",
    "organization is known for.\n",
    "My M.Tech in Data Science and Analytics has provided me with deep insights into machine\n",
    "learning, data analysis, and predictive modeling. Although my professional experience at Vinz\n",
    "Global and Aventior Digital Pvt Ltd primarily involved software development, these roles honed my\n",
    "technical expertise, particularly in backend development, API improvement, and database\n",
    "migration. These experiences have given me a solid understanding of the full software development\n",
    "lifecycle, which is crucial for building and optimizing data pipelines, implementing machine\n",
    "learning models, and deploying data-driven applications.\n",
    "One of my significant academic projects involved developing a skin cancer detection and\n",
    "classification model using convolutional neural networks (CNNs). This project not only enhanced\n",
    "my machine learning skills but also highlighted the importance of accuracy and innovation in\n",
    "developing life-impacting solutions. Additionally, my work on a diamond price prediction model\n",
    "using linear regression demonstrated my ability to analyze complex datasets and create precise,\n",
    "data-driven forecasts.\n",
    "I am particularly enthusiastic about this role because it offers the opportunity to transition my strong\n",
    "technical foundation and passion for data science into a position focused on developing and\n",
    "optimizing AI solutions. I am eager to collaborate with your multi-functional team, leverage my\n",
    "problem-solving skills, and contribute to driving the success of your AI-assisted decision-making\n",
    "processes.\n",
    "Thank you for considering my application. I am looking forward to the opportunity to discuss how\n",
    "my background in software development, combined with my academic focus on data science, can\n",
    "contribute to the innovative projects. Please feel free to contact me at 8668566528 or via email at\n",
    "abhisw28@gmail.com to schedule an interview.\n",
    "Sincerely,\n",
    "Abhishek Waghchaure\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    corpus = []\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        review = re.sub('[^a-zA-z]', \" \", sentence)\n",
    "        review = review.lower()\n",
    "        words = nltk.word_tokenize(review)\n",
    "        processed = [word for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "        processed_sentences = \" \".join(processed)\n",
    "        corpus.append(processed_sentences)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = preprocess_text(parahagraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in corpus:\n",
    "    words = nltk.word_tokenize(sent)\n",
    "    for word in words:\n",
    "        word_to_idx = {word : i for i , word in enumerate(words)}\n",
    "        inputs = torch.tensor([word_to_idx[word] for word in words])\n",
    "    embedding = nn.Embedding(num_embeddings=len(words),embedding_dim=10)\n",
    "    output = embedding(inputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7164,  0.8403, -1.0668,  1.1681,  0.0516, -0.5711,  1.3964, -1.4619,\n",
       "         -0.9122,  0.7886],\n",
       "        [-0.2805,  0.0951, -0.0612, -0.2269,  0.8538, -0.5986, -0.4218, -1.0404,\n",
       "          0.7541, -0.0618],\n",
       "        [ 1.9585, -0.1569,  1.7823,  0.1100, -1.2229,  1.3297, -0.1190,  0.0184,\n",
       "         -0.5252,  1.4983]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded sentence 1: tensor([[ 4.1359e-01, -9.3127e-01,  9.9078e-01,  7.3158e-01, -6.4504e-01,\n",
      "          3.0031e+00,  2.7077e-01, -1.3190e+00, -2.5058e-01,  1.9909e+00],\n",
      "        [-7.8162e-01, -1.1957e+00, -6.6741e-01, -7.3805e-01, -1.7215e+00,\n",
      "          4.4403e-01,  2.5435e-01, -3.8596e-01, -4.8750e-01,  1.1310e+00],\n",
      "        [-4.5331e-01, -4.8157e-01,  5.7394e-01, -2.2207e+00, -6.4993e-01,\n",
      "         -3.1225e-01,  1.7106e-01, -6.5593e-01,  5.5915e-01,  1.2136e+00],\n",
      "        [-9.5653e-01, -3.4757e-01,  1.6594e+00, -9.9075e-01, -1.9534e-01,\n",
      "          4.1454e-02, -5.0242e-01,  1.4129e+00, -3.2158e-01,  2.2678e-01],\n",
      "        [ 1.1930e+00,  8.2568e-01, -2.0238e+00, -7.1440e-01, -2.0327e-01,\n",
      "          1.2014e+00,  6.3158e-01,  2.0822e+00,  1.2114e+00, -1.3617e-01],\n",
      "        [ 1.1839e+00, -3.4127e-01, -1.2143e-03, -6.9045e-01,  9.6560e-03,\n",
      "          4.6977e-01,  1.5594e+00, -2.4775e+00, -7.9106e-01, -1.6960e+00],\n",
      "        [ 3.4047e-01, -1.9253e+00,  4.9490e-01, -3.1017e-01, -1.9429e+00,\n",
      "          3.1252e-01, -1.7002e+00, -1.2938e+00,  1.7003e+00, -8.1087e-01],\n",
      "        [ 3.5366e-01,  9.1787e-01,  1.5745e+00,  5.6606e-01, -2.3755e+00,\n",
      "          6.3289e-01, -1.2343e+00,  7.1932e-01,  1.6929e-01,  4.4993e-01],\n",
      "        [ 1.1974e+00, -1.1649e-01,  8.2200e-02,  5.3767e-01,  5.6880e-01,\n",
      "         -1.7757e-01, -1.8998e-01, -1.2987e+00, -6.6795e-01,  1.2910e+00],\n",
      "        [-6.9844e-01,  1.1110e+00, -1.2054e+00,  2.3661e-01, -7.2879e-01,\n",
      "         -6.8091e-01,  5.1182e-02, -1.2155e+00, -2.8395e-01,  8.2863e-01],\n",
      "        [ 3.4020e-01, -5.9666e-01, -7.4431e-01,  4.2950e-01, -3.2469e-01,\n",
      "         -2.1832e+00, -8.5064e-01,  8.2821e-02, -1.0395e+00,  1.0538e+00],\n",
      "        [-4.4345e-01, -1.4924e+00, -4.2099e-01, -4.8383e-01,  2.9211e-01,\n",
      "          1.1359e+00, -8.0556e-01, -1.6007e-01, -1.1939e+00,  1.9087e+00],\n",
      "        [-4.0562e-01,  9.0337e-02, -5.5283e-01, -1.6785e-01,  1.3060e+00,\n",
      "          1.2550e-01, -1.1352e+00,  7.4597e-01, -8.1737e-01,  3.0498e-01],\n",
      "        [-7.9688e-01, -9.8393e-01,  1.0457e+00,  2.5051e-01, -3.7878e-03,\n",
      "         -1.4912e-01,  6.6715e-01, -2.3682e+00, -1.6310e+00,  4.1035e-01],\n",
      "        [-1.9456e+00,  5.9992e-01, -2.0712e+00, -7.0353e-01,  1.1953e+00,\n",
      "          2.3865e-01,  1.5323e+00, -2.4143e-01, -3.3098e-01,  1.0805e+00],\n",
      "        [-9.4347e-01, -1.4705e+00,  1.4541e+00,  1.8855e-01, -2.3566e+00,\n",
      "          6.5035e-01,  7.7940e-01,  1.2657e+00, -6.9242e-01,  3.2481e-01],\n",
      "        [ 5.3952e-01,  7.3698e-01, -1.8318e+00,  2.0854e-01, -1.0353e+00,\n",
      "          1.1214e+00,  6.4303e-01, -5.3543e-01, -3.3124e-01,  3.2634e-01],\n",
      "        [ 2.7237e-01, -1.4876e+00, -3.7168e-01,  4.5298e-01, -1.2515e-01,\n",
      "         -3.5442e-01,  4.4082e-01,  1.2677e+00,  2.1046e-01, -1.2556e-01],\n",
      "        [ 1.7383e+00,  2.4298e-01,  1.7382e+00, -1.1609e+00,  9.0346e-01,\n",
      "          1.7535e-01, -1.4385e+00, -1.7732e+00,  4.0063e-02,  3.7894e-01],\n",
      "        [ 8.5712e-01, -1.4900e+00, -7.0671e-01,  2.0508e+00, -8.2757e-01,\n",
      "          3.4223e-01, -1.6326e-01, -1.3408e+00, -2.4461e-01, -3.2567e-01],\n",
      "        [ 1.1797e+00, -4.3071e-01, -1.2889e+00,  4.9472e-01, -8.5856e-02,\n",
      "         -9.0022e-01,  8.3862e-02,  7.8890e-01, -3.4628e-01,  1.7375e+00],\n",
      "        [ 4.7340e-01,  1.4118e+00, -8.4923e-01, -1.4169e+00,  1.4539e+00,\n",
      "          7.5350e-03, -1.9201e-01,  1.0028e-01,  1.0958e+00, -6.4305e-01],\n",
      "        [-1.2843e+00, -9.9418e-01, -8.6615e-01, -5.9635e-01,  7.7563e-01,\n",
      "          9.7957e-01,  2.3730e-01,  2.0048e-02, -7.2486e-01, -3.3218e-01],\n",
      "        [ 1.1833e-01, -1.3540e+00,  1.8790e+00, -4.8580e-01, -7.6905e-02,\n",
      "          1.3626e+00, -4.8683e-01, -1.8863e+00,  1.0362e+00, -9.8593e-01],\n",
      "        [ 4.3010e-01,  2.3782e-01, -6.9271e-02,  8.0121e-01, -1.7687e-01,\n",
      "         -1.7074e+00,  9.6275e-01,  1.6486e+00,  3.3948e-01,  1.0459e+00],\n",
      "        [-1.6720e-01,  1.6190e-01,  2.1740e-01, -7.2417e-01,  9.4705e-01,\n",
      "         -1.4657e+00,  1.1140e+00, -2.4218e+00, -2.3406e-01, -2.3564e+00],\n",
      "        [ 1.1181e+00,  9.1719e-01,  1.5275e-01, -1.6817e+00, -1.7391e+00,\n",
      "         -9.7605e-02,  7.5826e-01,  1.2326e+00,  1.0830e+00, -2.8798e+00],\n",
      "        [-7.3549e-01, -1.0208e+00,  3.3301e-01, -2.3932e-01,  8.5632e-01,\n",
      "          1.3139e+00,  8.7772e-01, -1.3898e+00, -1.1264e-01, -5.1063e-01],\n",
      "        [ 2.9718e-01,  1.2452e+00, -6.3455e-01, -8.0730e-01, -2.4163e-01,\n",
      "          2.1091e-01, -1.2099e+00, -1.0937e+00, -4.4360e-02,  1.9520e-01],\n",
      "        [-1.9634e-01,  1.1784e-01,  1.6839e+00,  9.0153e-01, -4.9464e-01,\n",
      "         -4.5227e-01,  1.8248e-01, -4.4948e-01, -1.3215e+00,  3.5079e-01],\n",
      "        [ 2.3934e+00, -2.5980e+00, -2.6975e-01, -1.1750e+00, -5.2367e-01,\n",
      "         -1.0755e+00,  1.7558e+00, -1.0531e+00, -4.8730e-01, -5.2664e-01]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 2: tensor([[ 2.4634e+00, -5.6476e-01,  1.0994e+00,  2.9705e-01,  2.6891e+00,\n",
      "          4.4834e-01,  5.4979e-01,  2.9657e-01, -4.4732e-02, -4.6562e-01],\n",
      "        [-3.5886e-01,  5.8454e-03,  1.6160e-01,  1.3382e+00, -6.4707e-01,\n",
      "         -1.2956e+00,  1.4436e+00, -4.3259e-02,  1.9246e+00, -8.6225e-01],\n",
      "        [-7.3829e-01, -3.0776e-01,  4.4584e-01, -4.4662e-01,  1.9327e+00,\n",
      "         -1.2653e-01, -1.7445e+00, -2.9282e-01, -8.0498e-01,  6.8293e-02],\n",
      "        [-7.3549e-01, -1.0208e+00,  3.3301e-01, -2.3932e-01,  8.5632e-01,\n",
      "          1.3139e+00,  8.7772e-01, -1.3898e+00, -1.1264e-01, -5.1063e-01],\n",
      "        [ 2.9718e-01,  1.2452e+00, -6.3455e-01, -8.0730e-01, -2.4163e-01,\n",
      "          2.1091e-01, -1.2099e+00, -1.0937e+00, -4.4360e-02,  1.9520e-01],\n",
      "        [ 4.4306e-01,  1.4333e-01,  4.1522e-01, -1.6778e+00, -4.4007e-01,\n",
      "         -2.7665e+00, -4.6899e-02,  4.3875e-02, -5.2455e-01, -2.0011e-02],\n",
      "        [-1.5716e+00, -1.2789e+00, -1.6168e+00,  2.6635e+00,  7.4658e-01,\n",
      "         -1.3636e+00,  1.9060e-01, -1.9545e+00, -7.2937e-01,  9.9533e-02],\n",
      "        [ 9.8671e-01, -8.0880e-02,  8.8580e-01,  4.4449e-01, -1.4095e+00,\n",
      "          1.1070e+00,  6.1056e-01,  1.5960e+00, -4.8768e-01, -6.0560e-01],\n",
      "        [-7.2599e-02,  1.2854e+00,  5.3436e-01,  4.0103e-02,  9.4271e-01,\n",
      "         -3.0344e-01,  9.2331e-01, -8.5642e-01,  6.1679e-02,  1.2765e+00],\n",
      "        [ 1.2268e+00,  1.5303e+00, -9.9660e-02, -7.5253e-01,  1.3215e-01,\n",
      "          1.4950e-01,  7.8156e-01,  3.8402e-02, -1.2672e-01,  1.1994e+00],\n",
      "        [-7.3210e-01,  1.1132e+00,  6.0754e-01,  1.0141e+00,  4.4540e-01,\n",
      "         -1.3584e+00,  1.2209e+00, -1.5651e+00,  6.2349e-01, -2.0285e+00],\n",
      "        [-6.6662e-01, -5.3558e-01, -3.1202e-01,  9.1574e-01, -2.1795e-01,\n",
      "         -7.9774e-01,  3.0926e-01,  1.3728e+00,  3.3854e-01,  1.3743e-01],\n",
      "        [ 3.5554e-01, -5.9403e-01,  1.0292e+00, -1.4214e+00,  6.9821e-01,\n",
      "          2.6028e-01,  7.2069e-01, -9.4905e-01, -3.2428e-01,  1.7638e+00],\n",
      "        [-6.8760e-02,  4.4091e-01,  1.6781e+00, -6.5707e-01,  4.0292e-01,\n",
      "         -2.3329e-01,  4.1071e-01, -5.8490e-01, -5.7350e-01,  7.3153e-02],\n",
      "        [ 4.3010e-01,  2.3782e-01, -6.9271e-02,  8.0121e-01, -1.7687e-01,\n",
      "         -1.7074e+00,  9.6275e-01,  1.6486e+00,  3.3948e-01,  1.0459e+00],\n",
      "        [ 7.4480e-01,  4.3862e-01,  1.0731e+00,  8.8156e-01,  5.0645e-01,\n",
      "         -2.4632e-01, -1.7483e-03, -7.3828e-01, -2.5791e-01, -1.2948e-01],\n",
      "        [ 1.3084e+00, -1.0709e+00, -8.8018e-02, -3.1376e-01,  4.2514e-01,\n",
      "          5.9586e-01,  1.4633e-01,  1.5840e+00,  2.7578e-01,  1.8953e+00],\n",
      "        [ 6.4200e-01,  7.2996e-01,  5.9184e-01, -1.7896e-01, -3.5650e-01,\n",
      "          1.3640e+00,  1.3822e+00, -3.5845e-01,  2.3348e-01,  1.9351e+00],\n",
      "        [ 2.0592e-02, -7.7789e-01,  1.0059e+00,  1.3171e-01,  9.9492e-01,\n",
      "         -2.2193e+00, -8.3692e-01,  6.5516e-01, -2.0700e-02, -7.5818e-01],\n",
      "        [-9.9377e-01,  8.2390e-01,  8.3625e-01, -5.3692e-01, -6.6303e-01,\n",
      "         -6.2688e-01,  2.4717e-01, -7.7534e-01,  3.1792e-01, -2.4312e-01],\n",
      "        [-8.0450e-01,  1.6864e-01,  3.8921e-01, -7.1184e-01, -8.7342e-01,\n",
      "          1.2988e+00,  1.4761e+00, -1.1810e+00,  1.6628e+00, -2.2254e+00],\n",
      "        [-8.3157e-01, -1.4306e+00,  9.0183e-01, -5.3597e-01, -6.3729e-01,\n",
      "         -1.2688e+00, -4.2968e-01, -1.5171e-01,  1.8700e+00,  3.3337e-01]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 3: tensor([[ 0.8157,  0.6541, -0.0577,  1.6578, -0.0664,  0.8433,  0.5170, -0.4564,\n",
      "         -0.4824,  0.2909],\n",
      "        [-0.7355, -1.0208,  0.3330, -0.2393,  0.8563,  1.3139,  0.8777, -1.3898,\n",
      "         -0.1126, -0.5106],\n",
      "        [ 0.2972,  1.2452, -0.6346, -0.8073, -0.2416,  0.2109, -1.2099, -1.0937,\n",
      "         -0.0444,  0.1952],\n",
      "        [ 0.4431,  0.1433,  0.4152, -1.6778, -0.4401, -2.7665, -0.0469,  0.0439,\n",
      "         -0.5246, -0.0200],\n",
      "        [ 1.2408,  1.2587, -0.2243, -0.4847,  0.4092,  0.0880,  0.0881, -0.3261,\n",
      "         -1.0275, -0.1085],\n",
      "        [-1.7311,  0.4350, -0.9950, -0.5565, -1.5620,  0.5599,  0.4810,  0.1083,\n",
      "         -1.2512, -0.1611],\n",
      "        [ 1.2915,  1.1044, -0.7652, -0.1333,  1.7748, -0.8181, -0.2922, -1.1968,\n",
      "          0.3620, -0.9418],\n",
      "        [ 0.6641,  0.5101,  0.6640,  1.5516,  1.4832, -1.3280,  0.5814, -1.1828,\n",
      "          0.4723, -0.5581],\n",
      "        [ 0.9044,  0.4859, -0.5938, -0.0064,  0.9997, -0.1278,  1.5515, -1.6680,\n",
      "         -0.9393, -0.5983],\n",
      "        [-0.7355, -1.0208,  0.3330, -0.2393,  0.8563,  1.3139,  0.8777, -1.3898,\n",
      "         -0.1126, -0.5106],\n",
      "        [ 2.4178,  0.8766, -0.2448,  0.3080, -0.1544,  0.2324,  0.1699,  0.9490,\n",
      "          0.0209, -0.5062],\n",
      "        [-0.2732, -0.2978, -0.1688, -0.0835, -0.4170,  1.2726, -1.1160,  0.6326,\n",
      "         -1.2931, -0.4240],\n",
      "        [-0.4668,  0.0053,  0.2163, -1.1275,  2.4421,  0.7505,  0.1551,  1.1789,\n",
      "         -0.4003, -0.1460]], grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 4: tensor([[ 0.0103, -0.0997, -0.6978,  1.4730, -0.9109, -0.5487,  0.4625,  2.0891,\n",
      "         -0.8085,  1.5970],\n",
      "        [-1.0679,  0.5220, -1.0734, -1.3293,  1.3482,  1.0452, -0.3785, -0.1430,\n",
      "         -0.5050, -0.1200],\n",
      "        [-0.0726,  1.2854,  0.5344,  0.0401,  0.9427, -0.3034,  0.9233, -0.8564,\n",
      "          0.0617,  1.2765],\n",
      "        [-0.2137,  0.2775, -0.7863,  0.5548,  0.1702,  0.4442, -0.5485,  0.3551,\n",
      "         -0.1390, -0.6592],\n",
      "        [ 1.6290, -2.1605, -1.7202,  0.9959, -0.9492,  1.3307,  0.2313,  0.3065,\n",
      "          1.1462, -0.3834],\n",
      "        [ 1.1767, -0.7737,  2.9511, -1.1927, -0.0813, -1.5706,  0.5331,  0.1538,\n",
      "         -0.7042, -1.2959],\n",
      "        [-0.3099,  0.4851, -0.7460, -0.2415, -1.2405, -1.5902,  0.8584,  1.7645,\n",
      "          0.1253, -1.2017],\n",
      "        [ 1.1962,  0.0193,  1.6345, -1.2968, -0.8104, -0.2462, -0.4644, -0.0164,\n",
      "         -0.9351, -0.9796],\n",
      "        [ 0.3554,  1.4576,  0.7137,  0.4606, -0.3245, -0.8414,  0.4530, -0.4713,\n",
      "         -0.0389, -0.3731],\n",
      "        [-2.9643,  0.3438,  0.9118, -0.3227, -0.3671, -0.1924, -0.4235, -0.6580,\n",
      "         -1.8695, -0.5297],\n",
      "        [-0.3224, -0.4018,  1.0757, -1.0233, -0.0334,  0.3730,  2.0985, -0.0503,\n",
      "          1.9083,  0.7589],\n",
      "        [ 1.2268,  1.5303, -0.0997, -0.7525,  0.1321,  0.1495,  0.7816,  0.0384,\n",
      "         -0.1267,  1.1994],\n",
      "        [-0.7264,  0.6371, -1.0585,  0.5799, -1.4543, -0.1642, -1.1367,  1.2173,\n",
      "         -0.6102,  0.0949],\n",
      "        [-1.1456, -1.2070,  0.2850, -0.3767,  0.8311, -1.0128, -0.8441,  1.3563,\n",
      "         -0.5089, -1.1376],\n",
      "        [ 0.6139,  1.0082, -0.0058, -0.3979, -0.8182, -0.7639, -2.5279,  2.1888,\n",
      "         -0.3896,  0.4173],\n",
      "        [ 0.9288, -0.7134,  1.0775,  0.7253, -1.0598, -0.4259,  0.3926, -0.7947,\n",
      "         -0.0987,  0.5942],\n",
      "        [ 0.1954, -1.7723, -1.1379,  1.3184,  0.2910, -0.0937,  0.4870,  0.9099,\n",
      "         -0.1459,  1.9033],\n",
      "        [ 0.4558,  0.1551,  1.8971, -0.4325, -0.1844, -2.0212, -0.9767,  0.2152,\n",
      "          1.0570, -0.6855],\n",
      "        [-0.4316, -1.5581, -0.3599, -1.0971,  1.5674,  0.7690,  0.7049,  1.5871,\n",
      "         -0.1894, -0.9205],\n",
      "        [-0.7264,  0.6371, -1.0585,  0.5799, -1.4543, -0.1642, -1.1367,  1.2173,\n",
      "         -0.6102,  0.0949],\n",
      "        [ 1.5679, -1.6201,  0.8038, -0.2304, -1.2066,  1.7954, -0.8171,  1.3836,\n",
      "         -0.9522,  0.4060],\n",
      "        [ 1.1775,  0.8214, -0.3351, -0.0669,  0.9069,  1.0714, -0.0122, -0.2923,\n",
      "         -1.1718, -0.3287],\n",
      "        [-0.6723, -0.4316, -0.1713,  1.2009, -1.4736,  0.4117, -0.5706, -0.3403,\n",
      "         -1.8848, -0.7020],\n",
      "        [ 0.0610,  0.0959,  0.4957,  0.3353, -0.1938,  0.2224,  1.1313, -1.3552,\n",
      "         -0.2225,  0.5332]], grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 5: tensor([[-1.2835,  0.3786, -1.3107, -0.8843, -0.3231, -0.5078, -0.9181, -0.7736,\n",
      "          0.3505,  0.2390],\n",
      "        [-1.2006,  0.7662, -1.1010, -0.6392, -0.4706,  0.5201, -0.9783,  0.6567,\n",
      "          1.0133, -0.3630],\n",
      "        [-1.7352, -0.1757, -0.2747, -0.3927, -0.6226,  1.3663, -0.1130, -0.0953,\n",
      "         -0.6300,  0.6354],\n",
      "        [-1.2052, -1.0952, -0.4485,  0.4223, -0.3251, -0.0957,  0.3250,  0.1958,\n",
      "          0.2322,  0.7089],\n",
      "        [ 2.5051,  0.7753, -0.9374, -1.7583, -0.6132, -0.7968,  0.8860, -0.3693,\n",
      "          1.1384, -1.4792],\n",
      "        [ 1.2268,  1.5303, -0.0997, -0.7525,  0.1321,  0.1495,  0.7816,  0.0384,\n",
      "         -0.1267,  1.1994],\n",
      "        [-0.7264,  0.6371, -1.0585,  0.5799, -1.4543, -0.1642, -1.1367,  1.2173,\n",
      "         -0.6102,  0.0949],\n",
      "        [-0.6381, -2.0783,  1.4783,  0.0781, -1.0104, -0.8013, -0.3934,  1.8358,\n",
      "          0.2734, -0.0357],\n",
      "        [ 1.4782, -0.5042, -2.1690, -0.4500, -0.3447, -0.3397,  0.3599,  0.2836,\n",
      "          1.4867,  1.0936],\n",
      "        [-1.4365,  0.1303, -0.5117, -1.8691, -1.9392, -1.5597,  0.2839, -0.6406,\n",
      "         -1.8530,  1.0234],\n",
      "        [-1.3518, -0.5510, -1.4855, -2.0799,  0.0776,  0.2445,  1.8960, -0.6636,\n",
      "         -0.2316,  0.9717],\n",
      "        [-0.7355, -1.0208,  0.3330, -0.2393,  0.8563,  1.3139,  0.8777, -1.3898,\n",
      "         -0.1126, -0.5106],\n",
      "        [ 1.3425,  1.0320,  0.0109, -0.0429, -2.7892,  1.3276, -0.4012, -0.5455,\n",
      "         -0.1567,  0.3640],\n",
      "        [-0.1013,  2.0569,  0.6115,  1.2747, -0.4233, -0.9651,  0.0480,  0.7172,\n",
      "          0.9906, -0.7921],\n",
      "        [ 0.6641,  0.5101,  0.6640,  1.5516,  1.4832, -1.3280,  0.5814, -1.1828,\n",
      "          0.4723, -0.5581],\n",
      "        [ 0.9044,  0.4859, -0.5938, -0.0064,  0.9997, -0.1278,  1.5515, -1.6680,\n",
      "         -0.9393, -0.5983],\n",
      "        [ 2.3491, -0.5605,  0.1985,  0.8141,  0.3555, -0.7692, -0.3105, -0.1101,\n",
      "          0.6541,  1.9685],\n",
      "        [ 0.0763,  1.2113, -0.3233, -0.7246,  0.2492, -0.2387,  0.8256, -1.3270,\n",
      "          1.0237, -1.5042],\n",
      "        [-0.7355, -1.0208,  0.3330, -0.2393,  0.8563,  1.3139,  0.8777, -1.3898,\n",
      "         -0.1126, -0.5106],\n",
      "        [ 0.0206, -0.7779,  1.0059,  0.1317,  0.9949, -2.2193, -0.8369,  0.6552,\n",
      "         -0.0207, -0.7582],\n",
      "        [ 0.2310, -1.4823, -1.0959, -0.4192, -2.1990, -0.2434,  0.5629, -0.5786,\n",
      "          1.3795,  0.7932]], grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 6: tensor([[-1.9834e+00, -1.6726e+00,  2.7761e-01,  1.7517e+00,  9.0676e-01,\n",
      "         -6.0990e-01,  1.1727e+00,  9.2310e-01,  3.7301e-01,  1.9758e-01],\n",
      "        [ 4.5732e-01, -1.3799e-01,  9.0624e-01, -9.4099e-01,  8.6306e-01,\n",
      "          1.3419e+00, -7.2592e-01, -2.9732e-01, -1.3366e+00, -5.6351e-01],\n",
      "        [-3.5886e-01,  5.8454e-03,  1.6160e-01,  1.3382e+00, -6.4707e-01,\n",
      "         -1.2956e+00,  1.4436e+00, -4.3259e-02,  1.9246e+00, -8.6225e-01],\n",
      "        [ 1.7639e-01,  8.3840e-02,  1.0042e+00, -1.0627e+00, -6.1006e-01,\n",
      "          7.4940e-01,  8.0543e-01, -1.3862e+00,  1.5055e+00, -2.4064e+00],\n",
      "        [-3.2244e-01, -4.0183e-01,  1.0757e+00, -1.0233e+00, -3.3415e-02,\n",
      "          3.7300e-01,  2.0985e+00, -5.0345e-02,  1.9083e+00,  7.5888e-01],\n",
      "        [-9.8691e-01,  4.4179e-01, -4.2170e-01, -7.6155e-01,  1.1521e+00,\n",
      "         -7.3940e-01,  1.6400e+00,  3.8670e-01,  1.0057e+00, -2.6833e+00],\n",
      "        [ 1.2538e+00, -1.2170e+00, -1.1021e-01,  1.4537e-01, -8.9765e-01,\n",
      "         -1.0373e-01, -3.2072e-01, -1.5184e+00,  4.9231e-01, -1.7700e+00],\n",
      "        [ 9.2452e-01,  1.4561e+00,  1.7685e+00,  7.4768e-01, -9.4355e-01,\n",
      "          6.2350e-01,  6.2060e-01, -1.6621e+00, -4.7383e-01, -3.8193e-02],\n",
      "        [-1.2129e+00,  5.4492e-01,  1.8440e+00,  9.0450e-01,  3.7799e-01,\n",
      "          1.5184e+00,  1.0790e+00,  9.9820e-01, -6.0449e-01,  1.7123e-01],\n",
      "        [-7.6450e-01,  6.7765e-01,  1.4822e+00, -2.8973e-01, -6.5982e-01,\n",
      "          1.0506e+00, -1.3090e+00,  7.1555e-03, -6.7852e-01,  9.0788e-01],\n",
      "        [ 3.4204e-02,  2.2919e-01,  1.2798e-01, -8.9786e-01, -1.6722e+00,\n",
      "          7.7457e-01,  1.3996e+00, -5.9366e-01,  2.8182e-01, -2.0636e-01],\n",
      "        [ 1.0733e-01,  2.2174e-01,  2.1709e+00,  2.5375e-01, -8.4216e-02,\n",
      "          8.3872e-01, -3.8896e-01,  1.9257e+00,  2.0441e+00,  6.3996e-01],\n",
      "        [ 7.8095e-01, -1.7225e+00, -1.0206e+00, -6.3850e-02, -9.2129e-01,\n",
      "          1.7420e+00,  1.4795e-03, -5.2945e-01,  3.3822e-01, -4.4338e-01],\n",
      "        [-9.4174e-01, -1.1202e+00,  1.3527e+00, -1.8316e+00,  8.0716e-01,\n",
      "         -1.5119e+00, -3.5859e-01,  1.4915e-01, -2.9807e+00,  4.8290e-02],\n",
      "        [-1.6347e-01,  2.0493e+00,  1.1128e+00,  1.2743e+00,  2.3260e-01,\n",
      "          1.1101e+00, -4.4654e-01, -3.2746e-01,  1.0248e+00,  2.9213e-01],\n",
      "        [ 1.7808e+00,  5.2932e-01,  3.5521e-01, -4.5515e-01, -7.5858e-01,\n",
      "          1.1466e+00,  4.4351e-02, -1.7306e+00,  8.1134e-01, -5.9541e-01]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 7: tensor([[ 1.0088, -0.0251,  0.7959, -1.3666, -0.6740, -0.9458,  0.0443, -1.2908,\n",
      "         -2.6521, -1.3050],\n",
      "        [ 1.7987,  1.4059, -0.4472, -0.6575, -0.7359, -0.5162,  0.7764,  1.0904,\n",
      "         -1.7531, -0.5412],\n",
      "        [ 0.6641,  0.5101,  0.6640,  1.5516,  1.4832, -1.3280,  0.5814, -1.1828,\n",
      "          0.4723, -0.5581],\n",
      "        [ 0.9044,  0.4859, -0.5938, -0.0064,  0.9997, -0.1278,  1.5515, -1.6680,\n",
      "         -0.9393, -0.5983],\n",
      "        [-0.0688,  0.4409,  1.6781, -0.6571,  0.4029, -0.2333,  0.4107, -0.5849,\n",
      "         -0.5735,  0.0732],\n",
      "        [-0.2116, -0.3615,  0.7868,  1.2561, -0.3640,  0.0056, -0.4714,  1.7447,\n",
      "          1.6662, -0.3358],\n",
      "        [ 0.3432,  0.7001,  1.1121, -1.3721, -0.3897,  1.6170, -0.1286,  0.0237,\n",
      "          0.1570, -0.2725],\n",
      "        [ 0.1838, -1.9612,  2.2172,  0.3198, -0.1534, -0.0820, -0.3637, -0.6248,\n",
      "          1.4066,  1.1276],\n",
      "        [ 0.7802, -0.3297,  0.4234,  0.4008, -0.0896,  0.1955, -0.3468,  0.0501,\n",
      "          0.3037,  1.4887],\n",
      "        [-0.4416,  3.6216,  1.4339,  1.8321,  0.5465, -1.5718,  0.5034,  0.2664,\n",
      "          0.9821,  0.0037],\n",
      "        [-0.9869,  0.4418, -0.4217, -0.7616,  1.1521, -0.7394,  1.6400,  0.3867,\n",
      "          1.0057, -2.6833],\n",
      "        [-1.3348, -1.1019, -0.1545,  0.6963, -0.9369, -1.0413, -2.5759,  0.2172,\n",
      "         -0.8758, -1.4038],\n",
      "        [ 0.9735, -1.7675, -1.1761, -1.4440,  0.7492,  1.3285,  2.4334,  0.3791,\n",
      "          0.4429, -1.1544],\n",
      "        [-0.9938,  0.8239,  0.8363, -0.5369, -0.6630, -0.6269,  0.2472, -0.7753,\n",
      "          0.3179, -0.2431]], grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 8: tensor([[ 1.9646,  0.7524, -0.5383,  0.5820,  1.4435, -2.6760, -1.3966, -0.6419,\n",
      "         -1.1465,  0.0625],\n",
      "        [ 0.9043,  0.4799, -0.2414,  2.1326, -2.1559, -0.6518, -1.0093, -0.4715,\n",
      "         -0.1256, -0.2748],\n",
      "        [-1.2078,  1.3413,  0.0372, -1.1046,  0.2668,  0.6758,  0.1904, -0.1639,\n",
      "         -2.1296,  0.3241],\n",
      "        [-0.8001, -0.2603,  0.1267, -0.1934, -0.5867, -0.9157,  0.4461,  0.3153,\n",
      "         -0.4786, -1.0460],\n",
      "        [ 0.9341, -0.6692, -0.1850, -0.9938,  0.3014, -2.4023, -0.3201, -0.4062,\n",
      "         -0.1380,  1.6005],\n",
      "        [ 0.0342,  0.2292,  0.1280, -0.8979, -1.6722,  0.7746,  1.3996, -0.5937,\n",
      "          0.2818, -0.2064],\n",
      "        [ 0.1073,  0.2217,  2.1709,  0.2537, -0.0842,  0.8387, -0.3890,  1.9257,\n",
      "          2.0441,  0.6400],\n",
      "        [ 0.6468, -0.5262, -0.2554,  0.5029, -0.4238, -0.1509, -1.5325,  0.4282,\n",
      "          1.7761, -0.2169],\n",
      "        [ 1.6549,  0.0820, -0.5622, -0.7104,  0.1758,  0.7712,  0.2247, -0.7529,\n",
      "         -0.8975,  0.1357],\n",
      "        [ 2.2840,  0.3933,  1.8878, -0.8284,  0.5654,  0.6710, -0.3157, -2.1434,\n",
      "         -0.2742,  1.9590],\n",
      "        [-0.2545, -0.9711, -0.8168, -0.8619,  0.6480, -1.1542, -1.6122,  0.8072,\n",
      "          1.5333,  0.0370],\n",
      "        [ 0.7160,  1.4702,  1.2791,  1.1822, -0.3907, -0.1858, -0.6110,  1.0828,\n",
      "         -1.4655, -0.3965],\n",
      "        [-1.2775, -0.4386,  0.6299,  1.5127,  0.5685, -1.5513,  0.0670, -0.2049,\n",
      "          0.3866, -1.1038],\n",
      "        [ 0.3733,  1.1873, -1.5783,  0.6182,  1.9922,  1.1782, -1.2646,  0.9157,\n",
      "         -0.0131, -0.2914],\n",
      "        [-0.1630,  0.2635,  0.5110, -1.1386,  0.4834,  1.7125,  2.2118,  0.1557,\n",
      "         -0.9686,  0.7718],\n",
      "        [-1.3305,  0.1386, -1.5067,  0.6738, -0.7949,  0.7687,  0.6634,  1.1112,\n",
      "          1.4135, -0.4416],\n",
      "        [-0.7355, -1.0208,  0.3330, -0.2393,  0.8563,  1.3139,  0.8777, -1.3898,\n",
      "         -0.1126, -0.5106],\n",
      "        [ 0.0206, -0.7779,  1.0059,  0.1317,  0.9949, -2.2193, -0.8369,  0.6552,\n",
      "         -0.0207, -0.7582],\n",
      "        [ 0.3495, -0.1586, -0.8543,  0.4237, -0.1878,  0.9033,  0.5933,  0.1759,\n",
      "          2.6097,  1.7605]], grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 9: tensor([[ 0.4558,  0.1551,  1.8971, -0.4325, -0.1844, -2.0212, -0.9767,  0.2152,\n",
      "          1.0570, -0.6855],\n",
      "        [-0.1267, -0.9782, -0.1185,  0.1474, -0.1884, -0.9511, -1.4616, -0.4769,\n",
      "         -0.9419,  0.8934],\n",
      "        [-0.1726, -0.9503, -2.3205,  1.4170, -1.7055, -0.4659, -0.0663,  0.6479,\n",
      "         -1.1462, -1.6881],\n",
      "        [-1.1822,  1.0975, -2.1015,  2.4514,  1.0084, -0.7197, -0.0483,  0.8724,\n",
      "          0.7817,  0.0036],\n",
      "        [-0.1347,  0.1807, -0.9009, -0.2210, -0.4511,  0.3058,  1.3548,  1.7196,\n",
      "          1.4242, -1.0054],\n",
      "        [-1.0355,  1.2693, -0.8837,  1.4276,  0.3086,  0.5429,  0.5635,  0.5838,\n",
      "          0.7101, -1.0874],\n",
      "        [ 2.4634, -0.5648,  1.0994,  0.2970,  2.6891,  0.4483,  0.5498,  0.2966,\n",
      "         -0.0447, -0.4656],\n",
      "        [ 0.9288, -0.7134,  1.0775,  0.7253, -1.0598, -0.4259,  0.3926, -0.7947,\n",
      "         -0.0987,  0.5942],\n",
      "        [-0.7383, -0.3078,  0.4458, -0.4466,  1.9327, -0.1265, -1.7445, -0.2928,\n",
      "         -0.8050,  0.0683],\n",
      "        [ 0.2067,  1.9167, -1.1142, -1.1829,  0.1980, -0.8808, -1.3882,  0.7708,\n",
      "          0.9098,  1.2612],\n",
      "        [-0.7355, -1.0208,  0.3330, -0.2393,  0.8563,  1.3139,  0.8777, -1.3898,\n",
      "         -0.1126, -0.5106],\n",
      "        [ 0.2972,  1.2452, -0.6346, -0.8073, -0.2416,  0.2109, -1.2099, -1.0937,\n",
      "         -0.0444,  0.1952],\n",
      "        [ 2.3934, -2.5980, -0.2698, -1.1750, -0.5237, -1.0755,  1.7558, -1.0531,\n",
      "         -0.4873, -0.5266],\n",
      "        [-0.4246, -1.4495, -0.3893, -0.4355,  0.4169,  0.4302, -0.6101, -1.6253,\n",
      "         -0.0757,  0.3404],\n",
      "        [-0.9869,  0.4418, -0.4217, -0.7616,  1.1521, -0.7394,  1.6400,  0.3867,\n",
      "          1.0057, -2.6833],\n",
      "        [-1.3518, -0.5510, -1.4855, -2.0799,  0.0776,  0.2445,  1.8960, -0.6636,\n",
      "         -0.2316,  0.9717],\n",
      "        [ 0.6420,  0.7300,  0.5918, -0.1790, -0.3565,  1.3640,  1.3822, -0.3585,\n",
      "          0.2335,  1.9351],\n",
      "        [-0.9938,  0.8239,  0.8363, -0.5369, -0.6630, -0.6269,  0.2472, -0.7753,\n",
      "          0.3179, -0.2431]], grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 10: tensor([[-6.6662e-01, -5.3558e-01, -3.1202e-01,  9.1574e-01, -2.1795e-01,\n",
      "         -7.9774e-01,  3.0926e-01,  1.3728e+00,  3.3854e-01,  1.3743e-01],\n",
      "        [-8.9855e-01,  3.6504e-01, -1.3333e+00, -1.8835e-01,  3.0699e-01,\n",
      "         -1.8173e-01,  1.0827e-02,  1.6895e+00, -6.6954e-01,  1.3049e+00],\n",
      "        [-8.3768e-01, -4.5477e-01, -8.2951e-01, -8.9732e-02, -4.6425e-01,\n",
      "         -6.5554e-01, -5.1771e-02,  5.9209e-02,  1.9248e+00,  1.9939e+00],\n",
      "        [-6.1519e-01,  1.5211e-01,  1.5765e+00, -2.1027e-01, -1.2486e+00,\n",
      "          5.9838e-01,  6.5604e-01,  1.5616e+00, -9.7106e-01, -2.7235e-01],\n",
      "        [ 4.3010e-01,  2.3782e-01, -6.9271e-02,  8.0121e-01, -1.7687e-01,\n",
      "         -1.7074e+00,  9.6275e-01,  1.6486e+00,  3.3948e-01,  1.0459e+00],\n",
      "        [-1.2402e+00, -1.7944e+00, -9.7808e-01, -1.3897e+00, -8.6411e-01,\n",
      "          3.1038e-01, -2.8257e+00, -4.7677e-04,  4.4923e-01, -1.1518e+00],\n",
      "        [ 3.2024e-02,  2.2053e+00,  7.9123e-03,  1.0508e-01,  1.6987e+00,\n",
      "         -1.2058e+00, -2.4694e-01, -1.0512e+00, -8.6250e-01, -5.5658e-01],\n",
      "        [ 1.4896e+00, -1.1772e+00,  1.1568e+00, -4.4624e-01,  3.4106e-01,\n",
      "          3.0182e-01,  3.9844e-01,  7.2254e-01,  5.4823e-01, -8.5911e-01],\n",
      "        [-6.8760e-02,  4.4091e-01,  1.6781e+00, -6.5707e-01,  4.0292e-01,\n",
      "         -2.3329e-01,  4.1071e-01, -5.8490e-01, -5.7350e-01,  7.3153e-02],\n",
      "        [ 7.4480e-01,  4.3862e-01,  1.0731e+00,  8.8156e-01,  5.0645e-01,\n",
      "         -2.4632e-01, -1.7483e-03, -7.3828e-01, -2.5791e-01, -1.2948e-01],\n",
      "        [ 1.9971e-02,  5.9270e-01,  7.6876e-01,  1.1263e+00, -1.3819e-01,\n",
      "         -1.0656e+00, -6.5633e-01,  3.9398e-01,  6.8990e-01,  6.2612e-01],\n",
      "        [-1.8820e+00, -6.8729e-01,  3.7128e-01, -4.0352e-01, -2.7341e+00,\n",
      "         -7.6259e-01, -5.2829e-01, -1.8739e-01,  1.3881e+00,  2.1329e+00],\n",
      "        [ 6.4200e-01,  7.2996e-01,  5.9184e-01, -1.7896e-01, -3.5650e-01,\n",
      "          1.3640e+00,  1.3822e+00, -3.5845e-01,  2.3348e-01,  1.9351e+00],\n",
      "        [-5.6812e-01, -4.3121e-01,  1.5818e+00, -3.3671e-01,  2.8195e-01,\n",
      "          7.8742e-01,  9.8578e-01,  1.0048e+00,  1.2197e+00,  1.7964e+00],\n",
      "        [ 8.6512e-01,  3.5279e-01,  1.5272e+00, -6.7244e-01, -1.4856e+00,\n",
      "         -6.3596e-01, -1.2835e-01,  3.3518e-01,  7.8120e-01,  1.8237e+00],\n",
      "        [-1.0538e+00, -1.8859e+00,  2.0918e-02,  1.2181e+00,  2.0726e+00,\n",
      "         -1.0191e+00, -9.8934e-01, -5.4624e-02,  9.5872e-01, -3.0252e-01],\n",
      "        [ 5.6112e-02,  5.5628e-01,  1.2208e-01,  2.1813e-01, -4.2039e-01,\n",
      "          1.2725e+00, -1.6764e+00,  1.2072e+00, -4.9129e-01,  1.1797e+00]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 11: tensor([[-0.2170,  0.2675, -2.6551,  0.4818, -0.4069,  0.7419, -0.3087, -1.1625,\n",
      "          1.3066, -0.0543],\n",
      "        [-0.6263, -0.3647, -0.5892,  0.0573, -0.2306,  0.6584,  0.9227,  0.7151,\n",
      "         -0.8196, -0.2873],\n",
      "        [ 1.1899,  0.2003, -0.1308,  0.5350,  1.1191,  1.4966,  1.1084,  0.8434,\n",
      "         -1.9410, -2.3266]], grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 12: tensor([[ 4.9787e-01,  1.0811e-01, -2.2545e-01, -9.4475e-01,  1.0128e+00,\n",
      "          1.1200e+00, -7.0867e-01,  1.4438e+00, -1.8652e+00,  7.2571e-02],\n",
      "        [-1.1079e+00,  1.1082e-02, -8.9669e-01,  9.7842e-02,  4.4694e-01,\n",
      "          1.3751e-01, -1.8521e+00,  5.9980e-01,  7.0810e-01,  2.8521e-01],\n",
      "        [-1.3473e-01,  1.8067e-01, -9.0088e-01, -2.2100e-01, -4.5114e-01,\n",
      "          3.0580e-01,  1.3548e+00,  1.7196e+00,  1.4242e+00, -1.0054e+00],\n",
      "        [ 5.3991e-01, -3.2231e-01,  6.5079e-01, -1.1447e+00, -2.0923e-01,\n",
      "          2.0919e+00, -1.7289e-01,  1.5973e+00,  1.9096e-01,  1.4414e-01],\n",
      "        [ 2.0310e-01,  1.1754e+00, -3.5032e-01, -3.2006e-01,  9.0640e-01,\n",
      "         -4.1741e-01, -1.9105e-01,  1.6181e-01,  3.1857e-02,  3.0273e-01],\n",
      "        [ 1.2268e+00,  1.5303e+00, -9.9660e-02, -7.5253e-01,  1.3215e-01,\n",
      "          1.4950e-01,  7.8156e-01,  3.8402e-02, -1.2672e-01,  1.1994e+00],\n",
      "        [-7.2636e-01,  6.3708e-01, -1.0585e+00,  5.7985e-01, -1.4543e+00,\n",
      "         -1.6421e-01, -1.1367e+00,  1.2173e+00, -6.1016e-01,  9.4896e-02],\n",
      "        [-2.1333e-02,  8.3291e-01,  1.4738e+00,  1.2704e+00,  1.1669e+00,\n",
      "          9.7876e-01,  1.0561e+00, -4.7233e-01, -2.2181e-02,  6.0537e-01],\n",
      "        [-3.5886e-01,  5.8454e-03,  1.6160e-01,  1.3382e+00, -6.4707e-01,\n",
      "         -1.2956e+00,  1.4436e+00, -4.3259e-02,  1.9246e+00, -8.6225e-01],\n",
      "        [ 1.1373e-01,  1.7799e+00, -1.6231e+00, -4.9210e-01, -1.4982e+00,\n",
      "          1.9248e+00,  2.5561e-01,  1.0935e+00, -2.0877e+00,  1.0509e+00],\n",
      "        [-7.3549e-01, -1.0208e+00,  3.3301e-01, -2.3932e-01,  8.5632e-01,\n",
      "          1.3139e+00,  8.7772e-01, -1.3898e+00, -1.1264e-01, -5.1063e-01],\n",
      "        [ 2.9718e-01,  1.2452e+00, -6.3455e-01, -8.0730e-01, -2.4163e-01,\n",
      "          2.1091e-01, -1.2099e+00, -1.0937e+00, -4.4360e-02,  1.9520e-01],\n",
      "        [ 7.4480e-01,  4.3862e-01,  1.0731e+00,  8.8156e-01,  5.0645e-01,\n",
      "         -2.4632e-01, -1.7483e-03, -7.3828e-01, -2.5791e-01, -1.2948e-01],\n",
      "        [ 1.3084e+00, -1.0709e+00, -8.8018e-02, -3.1376e-01,  4.2514e-01,\n",
      "          5.9586e-01,  1.4633e-01,  1.5840e+00,  2.7578e-01,  1.8953e+00],\n",
      "        [ 1.7639e-01,  8.3840e-02,  1.0042e+00, -1.0627e+00, -6.1006e-01,\n",
      "          7.4940e-01,  8.0543e-01, -1.3862e+00,  1.5055e+00, -2.4064e+00]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 13: tensor([[-6.6090e-02, -1.5871e+00, -1.3070e+00, -5.9070e-01, -5.2283e-01,\n",
      "         -9.1546e-02, -8.0496e-01, -4.7088e-01,  9.9227e-01,  2.1294e+00],\n",
      "        [-5.1553e-01, -5.4988e-01,  9.1361e-01,  1.9716e-03, -7.5504e-01,\n",
      "         -5.9067e-01,  8.9678e-01, -2.8376e-01, -7.5182e-01, -3.3119e-01],\n",
      "        [ 4.8186e-01,  4.3649e-01, -6.8967e-01,  1.2558e+00,  2.5184e-02,\n",
      "          1.0098e+00, -4.8900e-01,  1.3379e-01, -1.4544e+00,  8.1552e-01],\n",
      "        [-7.7598e-01, -1.5255e-01, -7.4114e-01,  7.3601e-01,  1.3920e+00,\n",
      "          8.7879e-02, -6.1254e-01, -1.3002e+00, -4.4193e-01, -1.2610e+00],\n",
      "        [ 1.3081e+00,  4.8490e-01, -1.6304e+00,  1.2859e+00, -5.9092e-01,\n",
      "         -1.5658e-01, -4.4296e-01, -1.8962e-01,  2.5202e-01, -7.5085e-02],\n",
      "        [ 5.3952e-01,  7.3698e-01, -1.8318e+00,  2.0854e-01, -1.0353e+00,\n",
      "          1.1214e+00,  6.4303e-01, -5.3543e-01, -3.3124e-01,  3.2634e-01],\n",
      "        [ 2.7237e-01, -1.4876e+00, -3.7168e-01,  4.5298e-01, -1.2515e-01,\n",
      "         -3.5442e-01,  4.4082e-01,  1.2677e+00,  2.1046e-01, -1.2556e-01],\n",
      "        [ 1.7383e+00,  2.4298e-01,  1.7382e+00, -1.1609e+00,  9.0346e-01,\n",
      "          1.7535e-01, -1.4385e+00, -1.7732e+00,  4.0063e-02,  3.7894e-01],\n",
      "        [ 8.5712e-01, -1.4900e+00, -7.0671e-01,  2.0508e+00, -8.2757e-01,\n",
      "          3.4223e-01, -1.6326e-01, -1.3408e+00, -2.4461e-01, -3.2567e-01],\n",
      "        [-1.7229e-01, -4.0111e-01, -4.3201e-01, -9.3217e-01, -2.7930e-01,\n",
      "          1.5167e+00, -9.7253e-01, -9.2571e-01, -1.1693e+00,  1.4112e+00],\n",
      "        [-1.4539e-01,  6.3517e-01, -2.4171e+00,  6.2022e-01,  3.9330e-02,\n",
      "         -1.4788e-01, -6.5909e-01, -9.7070e-01,  1.1554e+00, -2.7695e-01]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "Embedded sentence 14: tensor([[ 0.3688,  0.2382, -0.0169,  1.2420, -0.4671,  1.6993, -0.1388, -0.0182,\n",
      "          0.3115, -0.5925],\n",
      "        [ 0.4136, -0.9313,  0.9908,  0.7316, -0.6450,  3.0031,  0.2708, -1.3190,\n",
      "         -0.2506,  1.9909],\n",
      "        [-0.7816, -1.1957, -0.6674, -0.7380, -1.7215,  0.4440,  0.2544, -0.3860,\n",
      "         -0.4875,  1.1310]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    corpus = []\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        review = re.sub('[^a-zA-Z]', \" \", sentence)\n",
    "        review = review.lower()\n",
    "        words = nltk.word_tokenize(review)\n",
    "        processed = [word for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "        processed_sentence = \" \".join(processed)\n",
    "        corpus.append(processed_sentence)\n",
    "    return corpus\n",
    "\n",
    "\n",
    "corpus = preprocess_text(paragraph)\n",
    "\n",
    "# Step 1: Build vocabulary (word to index mapping) for the entire corpus\n",
    "all_words = [word for sentence in corpus for word in nltk.word_tokenize(sentence)]\n",
    "word_to_idx = {word: i for i, word in enumerate(set(all_words))}\n",
    "\n",
    "# Step 2: Convert sentences to sequences of indices\n",
    "indexed_sentences = [[word_to_idx[word] for word in nltk.word_tokenize(sentence)] for sentence in corpus]\n",
    "\n",
    "# Step 3: Define the embedding layer\n",
    "embedding_dim = 10\n",
    "embedding = nn.Embedding(num_embeddings=len(word_to_idx), embedding_dim=embedding_dim)\n",
    "\n",
    "# Step 4: Convert indexed sentences to tensors and apply embedding\n",
    "embedded_sentences = []\n",
    "for sentence in indexed_sentences:\n",
    "    inputs = torch.tensor(sentence)  # Convert sentence to tensor\n",
    "    output = embedding(inputs)  # Apply embedding\n",
    "    embedded_sentences.append(output)\n",
    "\n",
    "# Now `embedded_sentences` contains the embedded vectors for each sentence\n",
    "for i, emb_sentence in enumerate(embedded_sentences):\n",
    "    print(f\"Embedded sentence {i+1}: {emb_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "24\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(embedded_sentences[1]))\n",
    "print(len(embedded_sentences[3]))\n",
    "print(len(embedded_sentences[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
