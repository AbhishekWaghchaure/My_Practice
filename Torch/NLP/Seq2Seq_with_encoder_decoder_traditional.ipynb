{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c9a973a935d1b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T02:45:51.391467Z",
     "start_time": "2024-11-14T02:45:48.094669Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset,TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c8d60427175b40",
   "metadata": {},
   "source": [
    "## Only Seq2Seq model block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20ecc9788154bcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:48:17.038519Z",
     "start_time": "2024-11-14T11:48:17.033549Z"
    }
   },
   "outputs": [],
   "source": [
    "## Parameters\n",
    "output_size = 1000\n",
    "input_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e266b01ef7adfc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, hidden_size, embedding_size, p):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.drop_out = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(embedding_dim = embedding_size, num_embeddings = input_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,hidden_size, num_layers, dropout=p, batch_first = True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        # X shape = batch_size, sequence_length\n",
    "        embedding = self.embedding(x)\n",
    "        # embedding shape = batch_size, sequence_length, embedding_dimension/input_size\n",
    "        outputs, (hidden, cell) = self.lstm(embedding)\n",
    "        # output_dimension = num_layers, sequence_length, hidden_size \n",
    "        # hidden and cell state dimensions = num_layers, batch_size, hidden_size\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedding_size, num_layers, output_size, hidden_size, p): # output_size is vocab for the text to be translated\n",
    "        super(Decoder,self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(num_embeddings=output_size, embedding_dim = embedding_size)\n",
    "        \"\"\"embedding_size = [batch_size, sequ_length, embedding_size]  but we want only one word to come first\n",
    "            so the size should be [batch_size, 1, embedding_size]\"\"\"\n",
    "        self.lstm = nn.LSTM(embedding_size, num_layers, hidden_size, dropout=p, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self,x, hidden, cell):\n",
    "        x  = x.unsqueeze(1)\n",
    "        # Embedding_size = batch_size,1,embedding_size\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        \n",
    "        #shape of output = batch_size, 1, hidden_size\n",
    "        # shape of hidden and cell state num_layers,batch_size, hidden_size\n",
    "        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n",
    "        # shape of predictions = batch_size, 1, length of vocab(output_size)\n",
    "        predictions = self.fc(outputs)\n",
    "        predictions = predictions.squeeze(1)\n",
    "        \n",
    "        return predictions, hidden, cell\n",
    "        \n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, sos_idx, eos_idx, pad_idx):\n",
    "        super(Seq2Seq,self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sos_idx = sos_idx\n",
    "        self.eos_idx = eos_idx\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio = 0.5):\n",
    "        batch_size = source.size(0)\n",
    "        target_seq_len = target.size(1)\n",
    "        output_size = self.decoder.fc.output_size\n",
    "        outputs = torch.zeros(batch_size, target_seq_len, output_size)\n",
    "\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        # input = torch.full((batch_size,), self.sos_idx, dtype= torch.long)\n",
    "        input = target[:,0]\n",
    "\n",
    "        for t in range(1, target_seq_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:,t,:] = output\n",
    "\n",
    "            # Decide whether to use teacher forcing or not\n",
    "            teacher_force = torch.rand(1).item() < teacher_force_ratio\n",
    "\n",
    "            # Get the predicted token for the next time step (greedy decoding)\n",
    "            top1 = output.argmax(2)  # This is a tensor of shape (batch_size, 1)\n",
    "\n",
    "            # If the predicted token is <EOS>, stop the sequence generation\n",
    "            if top1 == self.eos_idx:\n",
    "                break\n",
    "\n",
    "            # Use teacher forcing or predicted token from the previous time step\n",
    "            input = target[:, t] if teacher_force else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f099312",
   "metadata": {},
   "source": [
    "## Training Loop For Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208045ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "batch_size =32\n",
    "\n",
    "# Model Hyperparameters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable_env_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
