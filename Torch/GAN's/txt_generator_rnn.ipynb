{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.589752Z",
     "start_time": "2024-10-27T10:01:47.583401Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.nn import BCELoss\n",
    "\n",
    "paragraph = \"\"\"Abhishek\n",
    "Waghchaure\n",
    "Sai Vrundavan, flat no-703, Sr No-56/5B,\n",
    "Behind Abhiruchi Mall, near Madhuli,\n",
    "Sinhgad road, Vadgaon Bk., PUNE,\n",
    "Maharashtra - 411041\n",
    "Email: abhisw28@gmail.com\n",
    "Mobile: 8668566528\n",
    "Professional Summary\n",
    "Data Scientist with a strong\n",
    "foundation in data science, machine\n",
    "learning, and analytics, reinforced by\n",
    "hands-on experience in Java\n",
    "development. Possessing an M.Tech\n",
    "in Data Science and Analytics, skilled\n",
    "in Python, data analysis, and\n",
    "creating machine learning models.\n",
    "Adept at translating complex data\n",
    "sets into actionable insights and\n",
    "committed to continuous learning\n",
    "and development in the data science\n",
    "field.\n",
    "Technical Skills\n",
    "Programming Languages: Python,\n",
    "Java\n",
    "Data Science & Analytics: Machine\n",
    "Learning, Data Analytics, Data\n",
    "Science, Natural Language\n",
    "Processing, Computer Vision,\n",
    "Business Analytics, Business\n",
    "Intelligence, Pandas, NumPy\n",
    "Web Development: HTML, CSS,\n",
    "JavaScript, React JS\n",
    "Frameworks & Tools: Spring Boot,\n",
    "Hibernate, RESTful API, J2EE,\n",
    "OpenCV, TensorFlow\n",
    "Languages: Marathi, English, Hindi\n",
    "Experience\n",
    "Java Developer | Vinz Global\n",
    "Jul 2022 - Dec 2023\n",
    "Outsourced to NICE, developed backend using\n",
    "Spring Microservices.\n",
    "Upgraded legacy systems from Java Servlets\n",
    "and JSPs to Spring and AngularJS.\n",
    "Migrated SQL queries to HQL in the DAO layer.\n",
    "Java Developer | Aventior Digital Pvt Ltd\n",
    "Oct 2021 - Jun 2022\n",
    "Developed and improved APIs for a healthcare\n",
    "project.\n",
    "Participated in the full SDLC including analysis,\n",
    "design, implementation, testing, and\n",
    "maintenance.\n",
    "Utilized Java, Spring Boot, Hibernate, REST, JSP,\n",
    "JavaScript, and JQuery.\n",
    "Intern Java Developer | Coding Bit\n",
    "Jun 2021 - Jul 2021\n",
    "Worked on a variety of small projects to\n",
    "enhance coding and development skills.\n",
    "Education\n",
    "M.Tech in Computer Science & Engineering - Data\n",
    "Science and Analytics\n",
    "MIT World Peace University, Pune, 2024\n",
    "PG Diploma. CDAC\n",
    "Institute for Advanced Computing and Software\n",
    "Development, Akurdi, Pune, 2022\n",
    "B.Tech in Computer Science & Engineering -\n",
    "MIT AOE, Alandi\n",
    "Projects\n",
    "Skin Cancer Detection and Classification using Deep\n",
    "Learning:\n",
    "Developed a novel approach using CNN architectures\n",
    "(DenseNet201, VGG16, Xception).\n",
    "Achieved high accuracy in classifying skin lesions,\n",
    "contributing to early diagnosis.\n",
    "Automatic Number Plate Detection using OpenCV\n",
    "and OCR:\n",
    "Implemented a detection system using the\n",
    "Haarcascade model and EasyOCR.\n",
    "Converted number plate images into text format.\n",
    "Diamond Price Prediction using Linear Regression:\n",
    "Predicted diamond prices based on various features\n",
    "using a linear regression model.\n",
    "Conducted comprehensive data analysis and model\n",
    "training.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8830ff40bf293e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.595790Z",
     "start_time": "2024-10-27T10:01:47.593364Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11bf6780173d88f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.614599Z",
     "start_time": "2024-10-27T10:01:47.612828Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40bea47483e15cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.630416Z",
     "start_time": "2024-10-27T10:01:47.627692Z"
    }
   },
   "outputs": [],
   "source": [
    "class text_data(Dataset):\n",
    "    def __init__(self,data):\n",
    "        super(text_data,self).__init__()\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95690d7046fbf1c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.644752Z",
     "start_time": "2024-10-27T10:01:47.642052Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(paragraph):\n",
    "    sentences = nltk.sent_tokenize(paragraph)\n",
    "    corpus = []\n",
    "    for sent in sentences:\n",
    "        review = re.sub(\"[^a-zA-z]\",\" \", sent)\n",
    "        review = review.lower()\n",
    "        words = nltk.word_tokenize(review)\n",
    "        words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "        preprocessed_text = \" \".join(words)\n",
    "        corpus.append(preprocessed_text)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941c07ed066ba19a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.679270Z",
     "start_time": "2024-10-27T10:01:47.657347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abhishek waghchaure sai vrundavan flat sr b behind abhiruchi mall near madhuli sinhgad road vadgaon bk pune maharashtra email abhisw gmail com mobile professional summary data scientist strong foundation data science machine learning analytics reinforced hands experience java development', 'possessing tech data science analytics skilled python data analysis creating machine learning models', 'adept translating complex data sets actionable insights committed continuous learning development data science field', 'technical skills programming languages python java data science analytics machine learning data analytics data science natural language processing computer vision business analytics business intelligence pandas numpy web development html css javascript react js frameworks tools spring boot hibernate restful api j ee opencv tensorflow languages marathi english hindi experience java developer vinz global jul dec outsourced nice developed backend using spring microservices', 'upgraded legacy systems java servlets jsps spring angularjs', 'migrated sql queries hql dao layer', 'java developer aventior digital pvt ltd oct jun developed improved apis healthcare project', 'participated full sdlc including analysis design implementation testing maintenance', 'utilized java spring boot hibernate rest jsp javascript jquery', 'intern java developer coding bit jun jul worked variety small projects enhance coding development skills', 'education tech computer science engineering data science analytics mit world peace university pune pg diploma', 'cdac institute advanced computing software development akurdi pune b tech computer science engineering mit aoe alandi projects skin cancer detection classification using deep learning developed novel approach using cnn architectures densenet vgg xception', 'achieved high accuracy classifying skin lesions contributing early diagnosis', 'automatic number plate detection using opencv ocr implemented detection system using haarcascade model easyocr', 'converted number plate images text format', 'diamond price prediction using linear regression predicted diamond prices based various features using linear regression model', 'conducted comprehensive data analysis model training']\n"
     ]
    }
   ],
   "source": [
    "corpus = preprocessing(paragraph)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff834318ac105d56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.700729Z",
     "start_time": "2024-10-27T10:01:47.697623Z"
    }
   },
   "outputs": [],
   "source": [
    "def embedding_generator(input_corpus, embedding_dim = 10, max_len = 20):\n",
    "    all_words = list(set(word for sent in input_corpus for word in nltk.word_tokenize(sent)))\n",
    "    # all_words = [words for sent in input_corpus for words in nltk.word_tokenize(sent)]\n",
    "    words_to_idx = {word : idx for idx, word in enumerate(all_words)}\n",
    "    \n",
    "    # indexed_sentences = [[words_to_idx[word] for word in nltk.word_tokenize(sent) ]for sent in input_corpus]\n",
    "    indexed_sentences = [[words_to_idx[word] for word in nltk.word_tokenize(sent) if word in words_to_idx] for sent in input_corpus]\n",
    "    \n",
    "    padded_sentences = [sent[:max_len] + [0] * (max_len - len(sent)) if len(sent) < max_len else sent[:max_len] for sent in indexed_sentences]\n",
    "    \n",
    "    \n",
    "    embedding_layer = nn.Embedding( num_embeddings = len(words_to_idx), embedding_dim = embedding_dim)\n",
    "    \n",
    "    embedded_corpus = []\n",
    "    for sentence in padded_sentences:\n",
    "        inputs = torch.tensor(sentence, dtype =torch.long)\n",
    "        outputs = embedding_layer(inputs)\n",
    "        embedded_corpus.append(outputs)\n",
    "        \n",
    "    return embedded_corpus, words_to_idx\n",
    "    \n",
    "    # print(all_words)\n",
    "    # print(words_to_idx)\n",
    "    # print(indexed_sentences)\n",
    "    # print(len(embedded_corpus[0]))\n",
    "    # print(len(indexed_sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73f40b3b004edc9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.717583Z",
     "start_time": "2024-10-27T10:01:47.712779Z"
    }
   },
   "outputs": [],
   "source": [
    "embedded_corpus, word_to_idx = embedding_generator(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee2cda8d5ec9cedb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.731118Z",
     "start_time": "2024-10-27T10:01:47.728874Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1751b9b1814642be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.747037Z",
     "start_time": "2024-10-27T10:01:47.742773Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "num_layers = 2\n",
    "hidden_size = 32\n",
    "batch_size = 6\n",
    "sequence_length = 20\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, vocab_size, sequence_length):\n",
    "        super(Generator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "        # RNN layer for generating sequences\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        # Output layer to transform hidden states to vocabulary space\n",
    "        self.output_layer = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)  # Initial hidden state\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.output_layer(out)\n",
    "        return out  # Shape: [batch_size, seq_length, vocab_size]\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, sequence_length):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "        # RNN layer for sequence processing\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        # Output layer for binary classification\n",
    "        self.output_layer = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)  # Initial hidden state\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # Take the last hidden state for binary classification\n",
    "        out = self.output_layer(out[:, -1, :])  # Shape: [batch_size, 1]\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fea9a25976eed7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.761122Z",
     "start_time": "2024-10-27T10:01:47.758505Z"
    }
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(embedded_corpus, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "898c046b9346a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.778213Z",
     "start_time": "2024-10-27T10:01:47.774502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 20, 10])\n",
      "torch.Size([6, 20, 10])\n",
      "torch.Size([5, 20, 10])\n"
     ]
    }
   ],
   "source": [
    "for data in data_loader:\n",
    "    print(data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2de47086c0430050",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.802446Z",
     "start_time": "2024-10-27T10:01:47.797774Z"
    }
   },
   "outputs": [],
   "source": [
    "## Training Loop for discriminator\n",
    "def train_gan(generator, discriminator, dataloader, num_epochs = epochs, lr = lr):\n",
    "    criterion = BCELoss()\n",
    "    g_optimizer = optim.Adam(generator.parameters(), lr = lr)\n",
    "    d_optimizer = optim.Adam(discriminator.parameters(), lr = lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_d_loss =0.0\n",
    "        epoch_g_loss=0.0\n",
    "        total_batches =len(data_loader)\n",
    "        \n",
    "        pbar = tqdm(total =total_batches, unit = 'batch')\n",
    "        for real_data in data_loader:\n",
    "            real_data = real_data.to(device= device)\n",
    "            \n",
    "            # Train Descriminator\n",
    "            d_optimizer.zero_grad()\n",
    "            real_labels = torch.ones(real_data.size(0), 1).to(device=device)\n",
    "            d_real_loss = criterion(discriminator(real_data), real_labels)\n",
    "            \n",
    "            # Fake Data Generation\n",
    "            noise = torch.randn(real_data.size(0), generator.sequence_length, generator.hidden_size).to(device=device)\n",
    "            fake_data = generator(noise)\n",
    "            fake_labels = torch.zeros(fake_data.size(0),1).to(device=device)\n",
    "            d_fake_loss =  criterion(discriminator(fake_data),fake_labels)\n",
    "            \n",
    "            #Combining and back propogating the descriminator loss\n",
    "            d_loss = d_real_loss + d_fake_loss\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            #Train Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            g_loss = criterion (discriminator(fake_data), real_labels)\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            epoch_d_loss = epoch_d_loss + d_loss.items()\n",
    "            epoch_g_loss = epoch_g_loss + g_loss.items()\n",
    "            \n",
    "            pbar.desc(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "            pbar.set_postfix({'D Loss': d_loss.item(), 'G Loss': g_loss.item()})  # Display current losses\n",
    "            pbar.update(1)  \n",
    "            \n",
    "        avg_d_loss = epoch_d_loss / total_batches  # Average discriminator loss\n",
    "        avg_g_loss = epoch_g_loss / total_batches  # Average generator loss\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Avg D Loss: {avg_d_loss:.4f}, Avg G Loss: {avg_g_loss:.4f}\")  # Print average losses\n",
    "        \n",
    "        pbar.close()  # Close the progress bar\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e638b368a21ed62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.822950Z",
     "start_time": "2024-10-27T10:01:47.816282Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = Generator(input_size, num_layers,hidden_size, sequence_length ).to(device = device)\n",
    "discriminator = Discriminator(input_size, hidden_size, num_layers).to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e9bee93d39fb7c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:01:47.935281Z",
     "start_time": "2024-10-27T10:01:47.836235Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?batch/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 10, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m, in \u001b[0;36mtrain_gan\u001b[0;34m(generator, discriminator, dataloader, num_epochs, lr)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Fake Data Generation\u001b[39;00m\n\u001b[1;32m     22\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(real_data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), generator\u001b[38;5;241m.\u001b[39msequence_length, generator\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m---> 23\u001b[0m fake_data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m fake_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(fake_data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m),\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     25\u001b[0m d_fake_loss \u001b[38;5;241m=\u001b[39m  criterion(discriminator(fake_data),fake_labels)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     23\u001b[0m     h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# Initial hidden state\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(out)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1390\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1386\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m   1387\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m-> 1390\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1392\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\n\u001b[1;32m   1393\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1394\u001b[0m         hx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[1;32m   1402\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.10/site-packages/torch/nn/modules/rnn.py:361\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]\n\u001b[1;32m    360\u001b[0m ):\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m     expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/tensor/lib/python3.10/site-packages/torch/nn/modules/rnn.py:312\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m     )\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 10, got 2"
     ]
    }
   ],
   "source": [
    "train_gan(generator, discriminator, dataloader = data_loader,num_epochs = epochs, lr = lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable_env_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
