{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/abhishekwaghchaure/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "  parahagraph = \"\"\"World War II[b] or the Second World War (1 September 1939 – 2 September 1945) was a global conflict between two alliances: the Allies and the Axis powers. Nearly all of the world's countries, including all of the great powers, participated in the conflict, and many invested all available economic, industrial, and scientific capabilities in pursuit of total war, blurring the distinction between civilian and military resources. Aircraft played a major role, enabling the strategic bombing of population centres and delivery of the only two nuclear weapons ever used in war. It was by far the deadliest conflict in history, resulting in 70–85 million fatalities. Millions died due to genocides, including the Holocaust, as well as starvation, massacres, and disease. In the wake of Axis defeat, Germany, Austria, Japan and Korea were occupied, and war crime tribunals were conducted against German and Japanese leaders.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenized = nltk.sent_tokenize(parahagraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['World War II[b] or the Second World War (1 September 1939 – 2 September 1945) was a global conflict between two alliances: the Allies and the Axis powers.',\n",
       " \"Nearly all of the world's countries, including all of the great powers, participated in the conflict, and many invested all available economic, industrial, and scientific capabilities in pursuit of total war, blurring the distinction between civilian and military resources.\",\n",
       " 'Aircraft played a major role, enabling the strategic bombing of population centres and delivery of the only two nuclear weapons ever used in war.',\n",
       " 'It was by far the deadliest conflict in history, resulting in 70–85 million fatalities.',\n",
       " 'Millions died due to genocides, including the Holocaust, as well as starvation, massacres, and disease.',\n",
       " 'In the wake of Axis defeat, Germany, Austria, Japan and Korea were occupied, and war crime tribunals were conducted against German and Japanese leaders.']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(len(sent_tokenized))\n",
    "print(type(sent_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenized = [nltk.word_tokenize(words) for words in sent_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(type(word_tokenized))\n",
    "print(len(word_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['World',\n",
       "  'War',\n",
       "  'II',\n",
       "  '[',\n",
       "  'b',\n",
       "  ']',\n",
       "  'or',\n",
       "  'the',\n",
       "  'Second',\n",
       "  'World',\n",
       "  'War',\n",
       "  '(',\n",
       "  '1',\n",
       "  'September',\n",
       "  '1939',\n",
       "  '–',\n",
       "  '2',\n",
       "  'September',\n",
       "  '1945',\n",
       "  ')',\n",
       "  'was',\n",
       "  'a',\n",
       "  'global',\n",
       "  'conflict',\n",
       "  'between',\n",
       "  'two',\n",
       "  'alliances',\n",
       "  ':',\n",
       "  'the',\n",
       "  'Allies',\n",
       "  'and',\n",
       "  'the',\n",
       "  'Axis',\n",
       "  'powers',\n",
       "  '.'],\n",
       " ['Nearly',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'world',\n",
       "  \"'s\",\n",
       "  'countries',\n",
       "  ',',\n",
       "  'including',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'great',\n",
       "  'powers',\n",
       "  ',',\n",
       "  'participated',\n",
       "  'in',\n",
       "  'the',\n",
       "  'conflict',\n",
       "  ',',\n",
       "  'and',\n",
       "  'many',\n",
       "  'invested',\n",
       "  'all',\n",
       "  'available',\n",
       "  'economic',\n",
       "  ',',\n",
       "  'industrial',\n",
       "  ',',\n",
       "  'and',\n",
       "  'scientific',\n",
       "  'capabilities',\n",
       "  'in',\n",
       "  'pursuit',\n",
       "  'of',\n",
       "  'total',\n",
       "  'war',\n",
       "  ',',\n",
       "  'blurring',\n",
       "  'the',\n",
       "  'distinction',\n",
       "  'between',\n",
       "  'civilian',\n",
       "  'and',\n",
       "  'military',\n",
       "  'resources',\n",
       "  '.'],\n",
       " ['Aircraft',\n",
       "  'played',\n",
       "  'a',\n",
       "  'major',\n",
       "  'role',\n",
       "  ',',\n",
       "  'enabling',\n",
       "  'the',\n",
       "  'strategic',\n",
       "  'bombing',\n",
       "  'of',\n",
       "  'population',\n",
       "  'centres',\n",
       "  'and',\n",
       "  'delivery',\n",
       "  'of',\n",
       "  'the',\n",
       "  'only',\n",
       "  'two',\n",
       "  'nuclear',\n",
       "  'weapons',\n",
       "  'ever',\n",
       "  'used',\n",
       "  'in',\n",
       "  'war',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'was',\n",
       "  'by',\n",
       "  'far',\n",
       "  'the',\n",
       "  'deadliest',\n",
       "  'conflict',\n",
       "  'in',\n",
       "  'history',\n",
       "  ',',\n",
       "  'resulting',\n",
       "  'in',\n",
       "  '70–85',\n",
       "  'million',\n",
       "  'fatalities',\n",
       "  '.'],\n",
       " ['Millions',\n",
       "  'died',\n",
       "  'due',\n",
       "  'to',\n",
       "  'genocides',\n",
       "  ',',\n",
       "  'including',\n",
       "  'the',\n",
       "  'Holocaust',\n",
       "  ',',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'starvation',\n",
       "  ',',\n",
       "  'massacres',\n",
       "  ',',\n",
       "  'and',\n",
       "  'disease',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'the',\n",
       "  'wake',\n",
       "  'of',\n",
       "  'Axis',\n",
       "  'defeat',\n",
       "  ',',\n",
       "  'Germany',\n",
       "  ',',\n",
       "  'Austria',\n",
       "  ',',\n",
       "  'Japan',\n",
       "  'and',\n",
       "  'Korea',\n",
       "  'were',\n",
       "  'occupied',\n",
       "  ',',\n",
       "  'and',\n",
       "  'war',\n",
       "  'crime',\n",
       "  'tribunals',\n",
       "  'were',\n",
       "  'conducted',\n",
       "  'against',\n",
       "  'German',\n",
       "  'and',\n",
       "  'Japanese',\n",
       "  'leaders',\n",
       "  '.']]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/abhishekwaghchaure/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m words \u001b[38;5;129;01min\u001b[39;00m word_tokenized:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m      3\u001b[0m      stemmed_words \u001b[38;5;241m=\u001b[39m stemming\u001b[38;5;241m.\u001b[39mstem(words)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "for words in word_tokenized:\n",
    "    if words.lower() not in set(stopwords.words('english')):\n",
    "     stemmed_words = stemming.stem(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n",
      "war\n",
      "ii\n",
      "[\n",
      "b\n",
      "]\n",
      "second\n",
      "world\n",
      "war\n",
      "(\n",
      "1\n",
      "septemb\n",
      "1939\n",
      "–\n",
      "2\n",
      "septemb\n",
      "1945\n",
      ")\n",
      "global\n",
      "conflict\n",
      "two\n",
      "allianc\n",
      ":\n",
      "alli\n",
      "axi\n",
      "power\n",
      ".\n",
      "nearli\n",
      "world\n",
      "'s\n",
      "countri\n",
      ",\n",
      "includ\n",
      "great\n",
      "power\n",
      ",\n",
      "particip\n",
      "conflict\n",
      ",\n",
      "mani\n",
      "invest\n",
      "avail\n",
      "econom\n",
      ",\n",
      "industri\n",
      ",\n",
      "scientif\n",
      "capabl\n",
      "pursuit\n",
      "total\n",
      "war\n",
      ",\n",
      "blur\n",
      "distinct\n",
      "civilian\n",
      "militari\n",
      "resourc\n",
      ".\n",
      "aircraft\n",
      "play\n",
      "major\n",
      "role\n",
      ",\n",
      "enabl\n",
      "strateg\n",
      "bomb\n",
      "popul\n",
      "centr\n",
      "deliveri\n",
      "two\n",
      "nuclear\n",
      "weapon\n",
      "ever\n",
      "use\n",
      "war\n",
      ".\n",
      "far\n",
      "deadliest\n",
      "conflict\n",
      "histori\n",
      ",\n",
      "result\n",
      "70–85\n",
      "million\n",
      "fatal\n",
      ".\n",
      "million\n",
      "die\n",
      "due\n",
      "genocid\n",
      ",\n",
      "includ\n",
      "holocaust\n",
      ",\n",
      "well\n",
      "starvat\n",
      ",\n",
      "massacr\n",
      ",\n",
      "diseas\n",
      ".\n",
      "wake\n",
      "axi\n",
      "defeat\n",
      ",\n",
      "germani\n",
      ",\n",
      "austria\n",
      ",\n",
      "japan\n",
      "korea\n",
      "occupi\n",
      ",\n",
      "war\n",
      "crime\n",
      "tribun\n",
      "conduct\n",
      "german\n",
      "japanes\n",
      "leader\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stemming = PorterStemmer()\n",
    "for word in sent_tokenized:\n",
    "    if word.lower() not in set(stopwords.words('english')):\n",
    "        stemmed_word = stemming.stem(word)\n",
    "        print(stemmed_word)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sent_tokenized):\n\u001b[1;32m      2\u001b[0m     word_token \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mword_tokenize(sent_tokenized[i])\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m words \u001b[38;5;129;01min\u001b[39;00m word_token:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in len(sent_tokenized):\n",
    "    word_token = nltk.word_tokenize(sent_tokenized[i])\n",
    "    for words in word_token:\n",
    "        if words.lower() not in set(stopwords.words('english')):\n",
    "            stem_corpus = stemming.stem(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(type(stemmed_word))\n",
    "print(len(stemmed_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/abhishekwaghchaure/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/abhishekwaghchaure/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Perform stemming and print results for non-stopwords\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_tokenized:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words:\n\u001b[1;32m     26\u001b[0m         stemmed_word \u001b[38;5;241m=\u001b[39m stemming\u001b[38;5;241m.\u001b[39mstem(word)\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28mprint\u001b[39m(stemmed_word)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Ensure you have downloaded the necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Example text\n",
    "text = \"Hello! How are you? This is an example text.\"\n",
    "\n",
    "# Sentence tokenization\n",
    "sent_tokenized = sent_tokenize(text)\n",
    "\n",
    "# Word tokenization\n",
    "word_tokenized = [word_tokenize(sentence) for sentence in sent_tokenized]\n",
    "\n",
    "# Initialize the stemmer and stopwords list\n",
    "stemming = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Perform stemming and print results for non-stopwords\n",
    "for word in word_tokenized:\n",
    "    if word.lower() not in stop_words:\n",
    "        stemmed_word = stemming.stem(word)\n",
    "        print(stemmed_word)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
